{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\"> SQL Injection + </h1>\n",
    "<span> Chou@ibCher+</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\LENOVO\\Documents\\GitHub\\WAF-AI\n",
      "Data distribution\n",
      "injection_type\n",
      "LEGAL    15257\n",
      "SQL       3288\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Correct the path\n",
    "current_dir = os.getcwd()  \n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "print('Current directory:', parent_dir)\n",
    "\n",
    "# Define the file path\n",
    "df_path = os.path.join(parent_dir, 'data', 'processed', 'cleanedData.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "\n",
    "print('Data distribution')\n",
    "print(df['injection_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9599090133636622\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3062\n",
      "           1       1.00      0.69      0.82       455\n",
      "\n",
      "    accuracy                           0.96      3517\n",
      "   macro avg       0.98      0.85      0.90      3517\n",
      "weighted avg       0.96      0.96      0.96      3517\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\LENOVO\\\\Documents\\\\GitHub\\\\WAF-AI\\\\WAF\\\\vectorizer.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv(df_path, usecols=['payload', 'is_malicious', 'injection_type'])\n",
    "\n",
    "# Convert the 'payload' column to strings and fill NaN values\n",
    "df['payload'] = df['payload'].astype(str).fillna('')\n",
    "\n",
    "# Remove any empty data points\n",
    "df = df[df['payload'] != '']\n",
    "\n",
    "# Remove any duplicate payloads\n",
    "df = df.drop_duplicates(subset=['payload'])\n",
    "\n",
    "# Custom tokenization function to capture SQL injection patterns\n",
    "def custom_tokenizer(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Initialize the Count Vectorizer (Bag of Words) with custom tokenizer and n-grams\n",
    "count_vectorizer = CountVectorizer(min_df=1, tokenizer=custom_tokenizer, ngram_range=(1, 3))\n",
    "\n",
    "# Transform the 'payload' column\n",
    "X = count_vectorizer.fit_transform(df['payload'])\n",
    "\n",
    "# Define the target variable\n",
    "y = df['is_malicious']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Save the model and vectorizer\n",
    "\n",
    "modelPathSaving = os.path.join(parent_dir, 'WAF', 'nb.pkl')\n",
    "vectorizerPathSaving = os.path.join(parent_dir, 'WAF', 'vectorizer.pkl')\n",
    "\n",
    "joblib.dump(nb_classifier, modelPathSaving)\n",
    "joblib.dump(count_vectorizer, vectorizerPathSaving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Injection: verve -> Prediction: 0\n",
      "SQL Injection: helllo chouaib -> Prediction: 0\n",
      "SQL Injection: username -> Prediction: 0\n",
      "SQL Injection: password -> Prediction: 0\n",
      "SQL Injection: bounjour -> Prediction: 0\n",
      "SQL Injection: 1' OR '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' -- -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' ({ -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' /* -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' # -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='1 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' AND '1'='2 -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT NULL, NULL -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT username, password FROM users -> Prediction: 1\n",
      "SQL Injection: 1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns -> Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# SQL injection examples\n",
    "sql_injections = [\n",
    "    'verve',\n",
    "    'helllo chouaib',\n",
    "    'username',\n",
    "    'password',\n",
    "    'bounjour',\n",
    "    \"1' OR '1'='1\",\n",
    "    \"1' OR '1'='1' --\",\n",
    "    \"1' OR '1'='1' ({\",\n",
    "    \"1' OR '1'='1' /*\",\n",
    "    \"1' OR '1'='1' #\",\n",
    "    \"1' OR '1'='1' AND '1'='1\",\n",
    "    \"1' OR '1'='1' AND '1'='2\",\n",
    "    \"1' OR '1'='1' UNION SELECT NULL, NULL\",\n",
    "    \"1' OR '1'='1' UNION SELECT username, password FROM users\",\n",
    "    \"1' OR '1'='1' UNION SELECT table_name, column_name FROM information_schema.columns\"\n",
    "]\n",
    "\n",
    "# Transform the SQL injections using the vectorizer\n",
    "sql_injections_vectorized = count_vectorizer.transform(sql_injections).toarray()\n",
    "\n",
    "# Predict using the Naive Bayes model\n",
    "predictions = nb_classifier.predict(sql_injections_vectorized)\n",
    "\n",
    "# Print the predictions\n",
    "for i, sql in enumerate(sql_injections):\n",
    "    print(f\"SQL Injection: {sql} -> Prediction: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flask version: 3.0.3\n",
      "Scikit-learn version: 1.2.2\n",
      "Pandas version: 2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_2616\\115874684.py:3: DeprecationWarning: The '__version__' attribute is deprecated and will be removed in Flask 3.1. Use feature detection or 'importlib.metadata.version(\"flask\")' instead.\n",
      "  print(f\"Flask version: {flask.__version__}\")\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "import sklearn\n",
    "print(f\"Flask version: {flask.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
